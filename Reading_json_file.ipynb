{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96816ed7-b08a-4ca3-abb9-f99880c3535d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Overview\n",
    "\n",
    "This notebook will show you how to create and query a table or DataFrame that you uploaded to DBFS. [DBFS](https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html) is a Databricks File System that allows you to store data for querying inside of Databricks. This notebook assumes that you have a file already inside of DBFS that you would like to read from.\n",
    "\n",
    "This notebook is written in **Python** so the default cell type is Python. However, you can use different languages by using the `%LANGUAGE` syntax. Python, Scala, SQL, and R are all supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6482be4c-f067-47c9-b0ac-35c938b94601",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>_corrupt_record</th><th>emp_id</th><th>name</th><th>projects</th></tr></thead><tbody><tr><td>[</td><td>null</td><td>null</td><td>null</td></tr><tr><td>null</td><td>1</td><td>Alice</td><td>List(List(30, Alpha), List(10, Beta))</td></tr><tr><td>null</td><td>2</td><td>Bob</td><td>List(List(25, Alpha), List(15, Gamma))</td></tr><tr><td>null</td><td>3</td><td>Charlie</td><td>List(List(20, Alpha))</td></tr><tr><td>null</td><td>4</td><td>Diana</td><td>List(List(35, Delta), List(20, Alpha))</td></tr><tr><td>null</td><td>5</td><td>Ethan</td><td>List(List(40, Beta))</td></tr><tr><td>null</td><td>6</td><td>Fiona</td><td>List(List(22, Gamma))</td></tr><tr><td>null</td><td>7</td><td>George</td><td>List(List(28, Beta), List(12, Delta))</td></tr><tr><td>null</td><td>8</td><td>Hannah</td><td>List(List(16, Alpha))</td></tr><tr><td>null</td><td>9</td><td>Ivan</td><td>List(List(18, Gamma), List(8, Beta))</td></tr><tr><td>null</td><td>10</td><td>Jill</td><td>List(List(45, Delta))</td></tr><tr><td>null</td><td>11</td><td>Kevin</td><td>List(List(32, Alpha), List(6, Beta))</td></tr><tr><td>null</td><td>12</td><td>Laura</td><td>List(List(30, Gamma))</td></tr><tr><td>null</td><td>13</td><td>Mike</td><td>List(List(10, Alpha))</td></tr><tr><td>null</td><td>14</td><td>Nina</td><td>List(List(25, Delta), List(10, Gamma))</td></tr><tr><td>null</td><td>15</td><td>Oscar</td><td>List(List(22, Beta))</td></tr><tr><td>null</td><td>16</td><td>Pam</td><td>List(List(17, Alpha))</td></tr><tr><td>null</td><td>17</td><td>Quentin</td><td>List(List(24, Gamma))</td></tr><tr><td>null</td><td>18</td><td>Rachel</td><td>List(List(19, Delta))</td></tr><tr><td>null</td><td>19</td><td>Steve</td><td>List(List(26, Alpha), List(14, Beta))</td></tr><tr><td>null</td><td>20</td><td>Tina</td><td>List(List(21, Gamma))</td></tr><tr><td>  ]</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "[",
         null,
         null,
         null
        ],
        [
         null,
         1,
         "Alice",
         [
          [
           30,
           "Alpha"
          ],
          [
           10,
           "Beta"
          ]
         ]
        ],
        [
         null,
         2,
         "Bob",
         [
          [
           25,
           "Alpha"
          ],
          [
           15,
           "Gamma"
          ]
         ]
        ],
        [
         null,
         3,
         "Charlie",
         [
          [
           20,
           "Alpha"
          ]
         ]
        ],
        [
         null,
         4,
         "Diana",
         [
          [
           35,
           "Delta"
          ],
          [
           20,
           "Alpha"
          ]
         ]
        ],
        [
         null,
         5,
         "Ethan",
         [
          [
           40,
           "Beta"
          ]
         ]
        ],
        [
         null,
         6,
         "Fiona",
         [
          [
           22,
           "Gamma"
          ]
         ]
        ],
        [
         null,
         7,
         "George",
         [
          [
           28,
           "Beta"
          ],
          [
           12,
           "Delta"
          ]
         ]
        ],
        [
         null,
         8,
         "Hannah",
         [
          [
           16,
           "Alpha"
          ]
         ]
        ],
        [
         null,
         9,
         "Ivan",
         [
          [
           18,
           "Gamma"
          ],
          [
           8,
           "Beta"
          ]
         ]
        ],
        [
         null,
         10,
         "Jill",
         [
          [
           45,
           "Delta"
          ]
         ]
        ],
        [
         null,
         11,
         "Kevin",
         [
          [
           32,
           "Alpha"
          ],
          [
           6,
           "Beta"
          ]
         ]
        ],
        [
         null,
         12,
         "Laura",
         [
          [
           30,
           "Gamma"
          ]
         ]
        ],
        [
         null,
         13,
         "Mike",
         [
          [
           10,
           "Alpha"
          ]
         ]
        ],
        [
         null,
         14,
         "Nina",
         [
          [
           25,
           "Delta"
          ],
          [
           10,
           "Gamma"
          ]
         ]
        ],
        [
         null,
         15,
         "Oscar",
         [
          [
           22,
           "Beta"
          ]
         ]
        ],
        [
         null,
         16,
         "Pam",
         [
          [
           17,
           "Alpha"
          ]
         ]
        ],
        [
         null,
         17,
         "Quentin",
         [
          [
           24,
           "Gamma"
          ]
         ]
        ],
        [
         null,
         18,
         "Rachel",
         [
          [
           19,
           "Delta"
          ]
         ]
        ],
        [
         null,
         19,
         "Steve",
         [
          [
           26,
           "Alpha"
          ],
          [
           14,
           "Beta"
          ]
         ]
        ],
        [
         null,
         20,
         "Tina",
         [
          [
           21,
           "Gamma"
          ]
         ]
        ],
        [
         "  ]",
         null,
         null,
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "_corrupt_record",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "emp_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "projects",
         "type": "{\"type\":\"array\",\"elementType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"hours\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"project_name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"containsNull\":true}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# File location and type\n",
    "file_location = \"/FileStore/tables/sample.json\"\n",
    "file_type = \"json\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"TRUE\"\n",
    "first_row_is_header = \"TRUE\"\n",
    "delimiter = \",\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", infer_schema) \\\n",
    "  .option(\"header\", first_row_is_header) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .load(file_location)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "880fd12e-1a31-40c8-be80-fbbd6d9f1f8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n|   name|array_name|\n+-------+----------+\n|   null|    [null]|\n|  Alice|   [Alice]|\n|    Bob|     [Bob]|\n|Charlie| [Charlie]|\n|  Diana|   [Diana]|\n|  Ethan|   [Ethan]|\n|  Fiona|   [Fiona]|\n| George|  [George]|\n| Hannah|  [Hannah]|\n|   Ivan|    [Ivan]|\n|   Jill|    [Jill]|\n|  Kevin|   [Kevin]|\n|  Laura|   [Laura]|\n|   Mike|    [Mike]|\n|   Nina|    [Nina]|\n|  Oscar|   [Oscar]|\n|    Pam|     [Pam]|\n|Quentin| [Quentin]|\n| Rachel|  [Rachel]|\n|  Steve|   [Steve]|\n+-------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import array,array_contains,array_position,array_remove,col,expr\n",
    "df1=df.select(\"name\",array(col(\"name\")).alias(\"array_name\"))\n",
    "df1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f9b2bcb-672f-4885-bed4-af94603dba7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+-------+--------------------+-----+-----+-----+\n|_corrupt_record|emp_id|   name|            projects|alpha| Beta|Gamma|\n+---------------+------+-------+--------------------+-----+-----+-----+\n|              [|  null|   null|                null| null| null| null|\n|           null|     1|  Alice|[{30, Alpha}, {10...| true| true|false|\n|           null|     2|    Bob|[{25, Alpha}, {15...| true|false| true|\n|           null|     3|Charlie|       [{20, Alpha}]| true|false|false|\n|           null|     4|  Diana|[{35, Delta}, {20...| true|false|false|\n|           null|     5|  Ethan|        [{40, Beta}]|false| true|false|\n|           null|     6|  Fiona|       [{22, Gamma}]|false|false| true|\n|           null|     7| George|[{28, Beta}, {12,...|false| true|false|\n|           null|     8| Hannah|       [{16, Alpha}]| true|false|false|\n|           null|     9|   Ivan|[{18, Gamma}, {8,...|false| true| true|\n|           null|    10|   Jill|       [{45, Delta}]|false|false|false|\n|           null|    11|  Kevin|[{32, Alpha}, {6,...| true| true|false|\n|           null|    12|  Laura|       [{30, Gamma}]|false|false| true|\n|           null|    13|   Mike|       [{10, Alpha}]| true|false|false|\n|           null|    14|   Nina|[{25, Delta}, {10...|false|false| true|\n|           null|    15|  Oscar|        [{22, Beta}]|false| true|false|\n|           null|    16|    Pam|       [{17, Alpha}]| true|false|false|\n|           null|    17|Quentin|       [{24, Gamma}]|false|false| true|\n|           null|    18| Rachel|       [{19, Delta}]|false|false|false|\n|           null|    19|  Steve|[{26, Alpha}, {14...| true| true|false|\n+---------------+------+-------+--------------------+-----+-----+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "df2=df.withColumn(\"alpha\",expr(\"array_contains(transform(projects, x -> x.project_name), 'Alpha')\"))\\\n",
    "      .withColumn(\"Beta\",expr(\"array_contains(transform(projects, x ->x.project_name),'Beta')\"))\\\n",
    "      .withColumn(\"Gamma\",expr(\"array_contains(transform(projects,x->x.project_name),'Gamma')\")) \n",
    "df2.show()       \n",
    "\n",
    "df3=df2.select(\"projects\",\"alpha\",\"Beta\",\"Gamma\")\n",
    "df3.show(truncate=False)\n",
    "            \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e8b3d70-c375-4c5c-99c6-ae4ccfce9e2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+-------+--------------------+-----+-----+-----+--------------+\n|_corrupt_record|emp_id|   name|            projects|alpha| Beta|Gamma|projects_count|\n+---------------+------+-------+--------------------+-----+-----+-----+--------------+\n|              [|  null|   null|                null| null| null| null|            -1|\n|           null|     1|  Alice|[{30, Alpha}, {10...| true| true|false|             2|\n|           null|     2|    Bob|[{25, Alpha}, {15...| true|false| true|             2|\n|           null|     3|Charlie|       [{20, Alpha}]| true|false|false|             1|\n|           null|     4|  Diana|[{35, Delta}, {20...| true|false|false|             2|\n|           null|     5|  Ethan|        [{40, Beta}]|false| true|false|             1|\n|           null|     6|  Fiona|       [{22, Gamma}]|false|false| true|             1|\n|           null|     7| George|[{28, Beta}, {12,...|false| true|false|             2|\n|           null|     8| Hannah|       [{16, Alpha}]| true|false|false|             1|\n|           null|     9|   Ivan|[{18, Gamma}, {8,...|false| true| true|             2|\n|           null|    10|   Jill|       [{45, Delta}]|false|false|false|             1|\n|           null|    11|  Kevin|[{32, Alpha}, {6,...| true| true|false|             2|\n|           null|    12|  Laura|       [{30, Gamma}]|false|false| true|             1|\n|           null|    13|   Mike|       [{10, Alpha}]| true|false|false|             1|\n|           null|    14|   Nina|[{25, Delta}, {10...|false|false| true|             2|\n|           null|    15|  Oscar|        [{22, Beta}]|false| true|false|             1|\n|           null|    16|    Pam|       [{17, Alpha}]| true|false|false|             1|\n|           null|    17|Quentin|       [{24, Gamma}]|false|false| true|             1|\n|           null|    18| Rachel|       [{19, Delta}]|false|false|false|             1|\n|           null|    19|  Steve|[{26, Alpha}, {14...| true| true|false|             2|\n+---------------+------+-------+--------------------+-----+-----+-----+--------------+\nonly showing top 20 rows\n\n+--------------------+--------------+\n|            projects|projects_count|\n+--------------------+--------------+\n|                null|            -1|\n|[{30, Alpha}, {10...|             2|\n|[{25, Alpha}, {15...|             2|\n|       [{20, Alpha}]|             1|\n|[{35, Delta}, {20...|             2|\n|        [{40, Beta}]|             1|\n|       [{22, Gamma}]|             1|\n|[{28, Beta}, {12,...|             2|\n|       [{16, Alpha}]|             1|\n|[{18, Gamma}, {8,...|             2|\n|       [{45, Delta}]|             1|\n|[{32, Alpha}, {6,...|             2|\n|       [{30, Gamma}]|             1|\n|       [{10, Alpha}]|             1|\n|[{25, Delta}, {10...|             2|\n|        [{22, Beta}]|             1|\n|       [{17, Alpha}]|             1|\n|       [{24, Gamma}]|             1|\n|       [{19, Delta}]|             1|\n|[{26, Alpha}, {14...|             2|\n+--------------------+--------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import size\n",
    "df_len=df2.withColumn(\"projects_count\",size(\"projects\").alias(\"proj_len\"))\n",
    "df_len.show()\n",
    "df_size=df_len.select(\"projects\",\"projects_count\")\n",
    "df_size.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7114dbf7-8643-48e1-bcf4-50c574bfb637",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+--------------------------+\n|projects_without_Alpha    |projects                  |\n+--------------------------+--------------------------+\n|null                      |null                      |\n|[{10, Beta}]              |[{30, Alpha}, {10, Beta}] |\n|[{15, Gamma}]             |[{25, Alpha}, {15, Gamma}]|\n|[]                        |[{20, Alpha}]             |\n|[{35, Delta}]             |[{35, Delta}, {20, Alpha}]|\n|[{40, Beta}]              |[{40, Beta}]              |\n|[{22, Gamma}]             |[{22, Gamma}]             |\n|[{28, Beta}, {12, Delta}] |[{28, Beta}, {12, Delta}] |\n|[]                        |[{16, Alpha}]             |\n|[{18, Gamma}, {8, Beta}]  |[{18, Gamma}, {8, Beta}]  |\n|[{45, Delta}]             |[{45, Delta}]             |\n|[{6, Beta}]               |[{32, Alpha}, {6, Beta}]  |\n|[{30, Gamma}]             |[{30, Gamma}]             |\n|[]                        |[{10, Alpha}]             |\n|[{25, Delta}, {10, Gamma}]|[{25, Delta}, {10, Gamma}]|\n|[{22, Beta}]              |[{22, Beta}]              |\n|[]                        |[{17, Alpha}]             |\n|[{24, Gamma}]             |[{24, Gamma}]             |\n|[{19, Delta}]             |[{19, Delta}]             |\n|[{14, Beta}]              |[{26, Alpha}, {14, Beta}] |\n+--------------------------+--------------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import array_remove,expr\n",
    "df_remove=df_size.withColumn (\"projects_without_alpha\",\n",
    "    expr(\"filter(projects, x -> x.project_name != 'Alpha')\")\n",
    ")\n",
    "df1_remove=df_remove.select(\"projects_without_Alpha\",\"projects\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84d5dd2f-1484-4c58-ba62-763e274c03e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+-----------+\n|projects                  |Alpha_index|\n+--------------------------+-----------+\n|null                      |null       |\n|[{30, Alpha}, {10, Beta}] |1          |\n|[{25, Alpha}, {15, Gamma}]|1          |\n|[{20, Alpha}]             |1          |\n|[{35, Delta}, {20, Alpha}]|2          |\n|[{40, Beta}]              |0          |\n|[{22, Gamma}]             |0          |\n|[{28, Beta}, {12, Delta}] |0          |\n|[{16, Alpha}]             |1          |\n|[{18, Gamma}, {8, Beta}]  |0          |\n|[{45, Delta}]             |0          |\n|[{32, Alpha}, {6, Beta}]  |1          |\n|[{30, Gamma}]             |0          |\n|[{10, Alpha}]             |1          |\n|[{25, Delta}, {10, Gamma}]|0          |\n|[{22, Beta}]              |0          |\n|[{17, Alpha}]             |1          |\n|[{24, Gamma}]             |0          |\n|[{19, Delta}]             |0          |\n|[{26, Alpha}, {14, Beta}] |1          |\n+--------------------------+-----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import array_position,expr\n",
    "df_position=df_size.withColumn(\"Alpha_index\",\n",
    "                               expr(\"array_position(transform(projects, x -> x.project_name),'Alpha')\")\n",
    ")\n",
    "df_index=df_position.select(\"projects\",\"Alpha_index\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4176062e-cdc1-497f-91ad-89a67c21181b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+-------+--------------------+-----+-----+-----+--------------+-----------+\n|_corrupt_record|emp_id|   name|            projects|alpha| Beta|Gamma|projects_count|  projects_|\n+---------------+------+-------+--------------------+-----+-----+-----+--------------+-----------+\n|           null|     1|  Alice|[{30, Alpha}, {10...| true| true|false|             2|{30, Alpha}|\n|           null|     1|  Alice|[{30, Alpha}, {10...| true| true|false|             2| {10, Beta}|\n|           null|     2|    Bob|[{25, Alpha}, {15...| true|false| true|             2|{25, Alpha}|\n|           null|     2|    Bob|[{25, Alpha}, {15...| true|false| true|             2|{15, Gamma}|\n|           null|     3|Charlie|       [{20, Alpha}]| true|false|false|             1|{20, Alpha}|\n|           null|     4|  Diana|[{35, Delta}, {20...| true|false|false|             2|{35, Delta}|\n|           null|     4|  Diana|[{35, Delta}, {20...| true|false|false|             2|{20, Alpha}|\n|           null|     5|  Ethan|        [{40, Beta}]|false| true|false|             1| {40, Beta}|\n|           null|     6|  Fiona|       [{22, Gamma}]|false|false| true|             1|{22, Gamma}|\n|           null|     7| George|[{28, Beta}, {12,...|false| true|false|             2| {28, Beta}|\n|           null|     7| George|[{28, Beta}, {12,...|false| true|false|             2|{12, Delta}|\n|           null|     8| Hannah|       [{16, Alpha}]| true|false|false|             1|{16, Alpha}|\n|           null|     9|   Ivan|[{18, Gamma}, {8,...|false| true| true|             2|{18, Gamma}|\n|           null|     9|   Ivan|[{18, Gamma}, {8,...|false| true| true|             2|  {8, Beta}|\n|           null|    10|   Jill|       [{45, Delta}]|false|false|false|             1|{45, Delta}|\n|           null|    11|  Kevin|[{32, Alpha}, {6,...| true| true|false|             2|{32, Alpha}|\n|           null|    11|  Kevin|[{32, Alpha}, {6,...| true| true|false|             2|  {6, Beta}|\n|           null|    12|  Laura|       [{30, Gamma}]|false|false| true|             1|{30, Gamma}|\n|           null|    13|   Mike|       [{10, Alpha}]| true|false|false|             1|{10, Alpha}|\n|           null|    14|   Nina|[{25, Delta}, {10...|false|false| true|             2|{25, Delta}|\n+---------------+------+-------+--------------------+-----+-----+-----+--------------+-----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode,posexplode,explode_outer,posexplode_outer\n",
    "df_explode=df_len.withColumn(\"projects_\",explode(\"projects\").alias(\"project_explode\"))\n",
    "df_explode.show()\n",
    "#from pyspark.sql.functions import explode,posexplode,explode_outer,posexplode_outer\n",
    "#df_posex=df_len.withColumn(\"projects\",posexplode(\"projects\").alias(\"pro_ex\"))\n",
    "#df_posex1 = df_posex.select(\"projects.pos\", \"projects.col.hours\", \"projects.col.project_name\")\n",
    "#df_posex1.show()\n",
    "\n",
    "                           \n",
    "                \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87c336d1-9002-46fc-a505-e5daa15d21e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------+\n|projects_json                                                            |\n+-------------------------------------------------------------------------+\n|null                                                                     |\n|[{\"hours\":30,\"project_name\":\"Alpha\"},{\"hours\":10,\"project_name\":\"Beta\"}] |\n|[{\"hours\":25,\"project_name\":\"Alpha\"},{\"hours\":15,\"project_name\":\"Gamma\"}]|\n|[{\"hours\":20,\"project_name\":\"Alpha\"}]                                    |\n|[{\"hours\":35,\"project_name\":\"Delta\"},{\"hours\":20,\"project_name\":\"Alpha\"}]|\n|[{\"hours\":40,\"project_name\":\"Beta\"}]                                     |\n|[{\"hours\":22,\"project_name\":\"Gamma\"}]                                    |\n|[{\"hours\":28,\"project_name\":\"Beta\"},{\"hours\":12,\"project_name\":\"Delta\"}] |\n|[{\"hours\":16,\"project_name\":\"Alpha\"}]                                    |\n|[{\"hours\":18,\"project_name\":\"Gamma\"},{\"hours\":8,\"project_name\":\"Beta\"}]  |\n|[{\"hours\":45,\"project_name\":\"Delta\"}]                                    |\n|[{\"hours\":32,\"project_name\":\"Alpha\"},{\"hours\":6,\"project_name\":\"Beta\"}]  |\n|[{\"hours\":30,\"project_name\":\"Gamma\"}]                                    |\n|[{\"hours\":10,\"project_name\":\"Alpha\"}]                                    |\n|[{\"hours\":25,\"project_name\":\"Delta\"},{\"hours\":10,\"project_name\":\"Gamma\"}]|\n|[{\"hours\":22,\"project_name\":\"Beta\"}]                                     |\n|[{\"hours\":17,\"project_name\":\"Alpha\"}]                                    |\n|[{\"hours\":24,\"project_name\":\"Gamma\"}]                                    |\n|[{\"hours\":19,\"project_name\":\"Delta\"}]                                    |\n|[{\"hours\":26,\"project_name\":\"Alpha\"},{\"hours\":14,\"project_name\":\"Beta\"}] |\n+-------------------------------------------------------------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_json\n",
    "\n",
    "\n",
    "\n",
    "df_json = df.withColumn(\"projects_json\", to_json(col(\"projects\")))\n",
    "df_json.select(\"projects_json\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3372450561108975,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Reading_json_file",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}